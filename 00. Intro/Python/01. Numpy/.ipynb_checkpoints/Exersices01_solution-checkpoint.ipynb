{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises01.ipynb - Ejercicios Avanzados NumPy + Funciones/Clases + Archivos + Plots\n\n",
    "**Nivel: Alto** (algoritmos O(n log n), clases con herencia, broadcasting avanzado, I/O robusto).\n\n",
    "**Dataset:** Temperaturas Helsinki 2017 (https://raw.githubusercontent.com/csmastersUH/data_analysis_with_python_2020/master/kumpula-weather-2017.csv) [web:71][web:2]\n\n",
    "Integra:\n",
    "- NumPy: slicing, máscaras, polyfit, FFT.\n",
    "- Funciones/Clases: herencia, decoradores, métodos vectorizados.\n",
    "- Archivos: genfromtxt con dtype estructurado, savetxt procesado.\n",
    "- Plots: subplots, contourf, errorbars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial import Polynomial\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Carga Datos + Preprocesamiento NumPy (Medio-Alto)\n\n",
    "Carga temps de URL. Convierte mmm-dd a días desde inicio (dias = monthday_to_days).\n",
    "- Filtra NaNs/máscaras.\n",
    "- Calcula anomalías (temp - media móvil 30 días).\n",
    "- Detecta outliers (IQR método, Q1-1.5*IQR).\n",
    "**Output esperado:** `temps_clean` (N x 2), `dias` (N,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/csmastersUH/data_analysis_with_python_2020/master/kumpula-weather-2017.csv'\n",
    "# Tu código: np.genfromtxt(url, skip_header=1, usecols=(0,1), names=['mdate','temp'], dtype=None, delimiter=',', encoding='utf-8')\n",
    "# Parsing mdate 'MMM DD' -> días cumulativos (ej. ene1=1, feb1=32)\n",
    "# month_days = {'Jan':31, 'Feb':28, ...}; cumul_days\n",
    "# mask = ~np.isnan(temp)\n",
    "# rolling_mean = np.convolve(temp[mask], np.ones(30)/30, mode='same')\n",
    "# anomalies = temp[mask] - rolling_mean\n",
    "# Q1, Q3 = np.percentile(anomalies, [25,75]); iqr = Q3-Q1; outliers = np.abs(anomalies) > 1.5*iqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Clase Avanzada con Herencia/Decoradores (Alto)\n\n",
    "Crea **base class TimeSeriesAnalyzer**:\n",
    "- `smooth(self, window=7)`: media móvil.\n",
    "- Decorator `@vectorize` para aplicar funcs a columnas.\n\n",
    "**Clase hija WeatherAnalyzer** hereda + agrega:\n",
    "- `seasonal_decompose(self)`: trend (polyfit deg=2), seasonal (FFT top 4 freq), residual.\n",
    "- `forecast(self, days_ahead=30)`: ARIMA-like simple (últ 30 días polyfit deg=3) + ruido.\n",
    "**Usa:** `analyzer = WeatherAnalyzer(dias, temps_clean[:,1])` [web:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(method):\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        return np.array([method(self, col, *args, **kwargs) for col in self.data.T]).T\n",
    "    return wrapper\n",
    "\n",
    "class TimeSeriesAnalyzer:\n",
    "    def __init__(self, t, data):\n",
    "        self.t, self.data = t, data\n",
    "    \n",
    "    @vectorize\n",
    "    def smooth(self, col, window=7):\n",
    "        return np.convolve(col, np.ones(window)/window, mode='same')\n",
    "    \n",
    "# Herencia + seasonal_decompose (np.fft.fft, top freqs), forecast (np.polyfit)\n",
    "# analyzer = WeatherAnalyzer(dias, temps_clean)\n",
    "# smoothed = analyzer.smooth()\n",
    "# trend, seasonal, residual = analyzer.seasonal_decompose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: I/O Robusto + Procesado (Medio-Alto)\n\n",
    "- Guarda `temps_clean` + `anomalies` a 'processed_weather.npz' (np.savez).\n",
    "- Escribe subset (primeros 100 días, columnas: dias, temp_smooth, anomaly) a 'subset.csv' (savetxt, fmt='%.2f', header).\n",
    "- Función `load_and_validate(filename)`: carga npz/csv, chequea shape/inf/NaNs, retorna dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('processed_weather.npz', temps=temps_clean, anomalies=anomalies)\n",
    "# subset = np.column_stack([dias[:100], smoothed[0,:100], anomalies[:100]])\n",
    "# np.savetxt('subset.csv', subset, delimiter=',', header='day,temp_smooth,anomaly', fmt='%.3f')\n",
    "\n",
    "def load_and_validate(filename):\n",
    "    # Maneja .npz (load), .csv (genfromtxt); chequea np.isfinite.all(), shape==(?,3)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Visualizaciones Avanzadas (Alto)\n\n",
    "Fig 14x10 con 4 subplots:\n",
    "- (2,2)[0,0]: temp vs dias + smooth + polyfit deg=1 errorbars.\n",
    "- [0,1]: Anomalías hist + KDE (np.histogram).\n",
    "- [1,0]: Heatmap anomalías (plt.pcolormesh, meses bins).\n",
    "- [1,1]: Forecast 30 días + seasonal components.\n",
    "- Guarda 'advanced_analysis.png'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(14,10))\n",
    "# p0: plt.errorbar(dias, temp, yerr=std_smooth); pfit = np.polyfit(dias, temp,1); plt.plot(dias, np.polyval(pfit,dias))\n",
    "# p1: hist, kde = np.histogram(anoms, bins=50, density=True); axs[0,1].plot(np.linspace(min,max,50), kde_smooth)\n",
    "# p2: mesh = axs[1,0].pcolormesh(months_bins, temp_bins, anomalies_2d)\n",
    "# p3: forecast_line + seasonal sin/cos waves\n",
    "plt.savefig('advanced_analysis.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Desafío Final - Algoritmo Custom (Muy Alto)\n\n",
    "Implementa **cambio climático detector**:\n",
    "1. Divide en ventanas 90 días deslizantes.\n",
    "2. Polyfit deg=1 cada ventana → pendiente.\n",
    "3. Media móvil pendientes → trend_strength.\n",
    "4. Si >0.01°C/día y significativo (bootstrap 1000 resamples p<0.05), alerta.\n",
    "**Output:** dict{'trend':slope, 'pvalue':p, 'alerta':bool}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def climate_detector(t, temp, window=90, n_bootstrap=1000):\n",
    "    # Ventanas: np.lib.stride_tricks.sliding_window_view\n",
    "    # Para cada: polyfit(t_win, temp_win,1)[0] → slopes\n",
    "    # Bootstrap: resample con replacement, calc slope dist\n",
    "    # p = (n_pos_slopes / n_bootstrap) si trend>0\n",
    "    pass\n",
    "\n",
    "# result = climate_detector(dias, temps_clean[:,1])\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
