{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Astrofisica Computacional](../../../new_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dr. rer. nat. Jose Ivan Campos Rozo<sup>1,2</sup>\n",
    "\n",
    "1. Astronomical Institute of the Czech Academy of Sciences\\\n",
    "   Department of Solar Physics\\\n",
    "   Ondřejov, Czec Republic\n",
    "\n",
    "2. Observatorio Astronómico Nacional\\\n",
    "   Facultad de Ciencias\\\n",
    "   Universidad Nacional de Colombia\n",
    "\n",
    "e-mail: jicamposr@unal.edu.co & rozo@asu.cas.cz)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced NumPy Exercises + Functions/Classes + Files\n",
    "\n",
    "**Dataset:** Adapted from the Helsinki 2017 Temperatures dataset (https://raw.githubusercontent.com/csmastersUH/data_analysis_with_python_2020/master/kumpula-weather-2017.csv)\n",
    "\n",
    "Includes:\n",
    "- NumPy: slicing, masks, polyfit, FFT.\n",
    "\n",
    "- Functions/Classes: inheritance, decorators, vectorized methods.\n",
    "\n",
    "- Files: loadtxt, processed savetxt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Data Loading + NumPy Preprocessing\n",
    "\n",
    "Load temps from the file \"kumpula-weather-2017.csv\". Write a function to convert mm-dd to days since start (days = monthday_to_days).\n",
    "\n",
    "- Filter NaNs or infs/masks.\n",
    "\n",
    "- Calculate anomalies (temperature - 30-day moving average).\n",
    "\n",
    "- Detect outliers (IQR method, Q1-1.5*IQR).\n",
    "\n",
    "**Expected output:** `temps_clean` (N x 2), `dias` (N,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Advanced Class with Inheritance/Decorators \n",
    "\n",
    "Create a **base class TimeSeriesAnalyzer**:\n",
    "- `smooth(self, window=7)`: moving average.\n",
    "\n",
    "- Decorator `@vectorize` to apply functions to columns.\n",
    "\n",
    "**Child class WeatherAnalyzer** inherits and adds:\n",
    "- `seasonal_decompose(self)`: trend (polyfit deg=2), seasonal (FFT top 4 freq), residual.\n",
    "\n",
    "- `forecast(self, days_ahead=30)`: simple ARIMA-like (last 30 days, polyfit deg=3) + noise.\n",
    "\n",
    "- **Use:** `analyzer = WeatherAnalyzer(days, temps_clean[:,1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator to vectorize method over the columns\n",
    "def vectorize(method):\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        results = np.array([method(self, col, *args, **kwargs) for col in self.data.T]).T\n",
    "        return results if results.ndim > 1 else results.flatten()\n",
    "    return wrapper\n",
    "\n",
    "class TimeSeriesAnalyzer:\n",
    "    \"\"\"Clase base para análisis de series temporales con NumPy.\"\"\"\n",
    "    def __init__(self, t: np.ndarray, data: np.ndarray):\n",
    "        self.t = np.asarray(t)\n",
    "        self.data = np.asarray(data)\n",
    "        if self.t.shape[0] != self.data.shape[0]:\n",
    "            raise ValueError(\"t y data deben tener misma longitud\")\n",
    "    \n",
    "    @vectorize\n",
    "    def smooth(self, col: np.ndarray, window: int = 7, mode: str = 'same') -> np.ndarray:\n",
    "        \"\"\"Media móvil con convolve.\"\"\"\n",
    "        kernel = np.ones(window) / window\n",
    "        return np.convolve(col, kernel, mode=mode)\n",
    "    \n",
    "    def stats(self) -> dict:\n",
    "        \"\"\"Estadísticas básicas por columna.\"\"\"\n",
    "        return {\n",
    "            'mean': np.mean(self.data, axis=0),\n",
    "            'std': np.std(self.data, axis=0),\n",
    "            'min': np.min(self.data, axis=0),\n",
    "            'max': np.max(self.data, axis=0)\n",
    "        }\n",
    "\n",
    "class WeatherAnalyzer(TimeSeriesAnalyzer):\n",
    "    \"\"\"Hija especializada en datos meteorológicos.\"\"\"\n",
    "    def __init__(self, t: np.ndarray, data: np.ndarray):\n",
    "        super().__init__(t, data)\n",
    "    \n",
    "    def seasonal_decompose(self, degree_trend: int = 2, n_freqs: int = 4) -> dict:\n",
    "        \"\"\"Descomposición: trend (polyfit), seasonal (FFT top freqs), residual.\"\"\"\n",
    "        # Trend: polyfit global\n",
    "        p_trend = np.polynomial.Polynomial.fit(self.t, self.data, degree_trend)\n",
    "        trend = p_trend(self.t)\n",
    "        \n",
    "        # Seasonal: FFT, top n_freqs armónicos\n",
    "        fft = np.fft.fft(self.data - trend, axis=0)\n",
    "        freqs = np.fft.fftfreq(len(self.t))\n",
    "        top_idx = np.argsort(np.abs(fft), axis=0)[-n_freqs:][::-1]\n",
    "        seasonal = np.zeros_like(self.data)\n",
    "        for idx in top_idx[:]:\n",
    "            seasonal[:] += 2 * np.real(np.fft.ifft(fft[:] * (np.abs(fft[idx]) > 1e-3)))\n",
    "        \n",
    "        residual = self.data - trend - seasonal\n",
    "        return {'trend': trend, 'seasonal': seasonal, 'residual': residual}\n",
    "    \n",
    "    def forecast(self, days_ahead: int = 30, degree: int = 3, noise_std: float = 1.0) -> tuple:\n",
    "        \"\"\"Pronóstico simple: polyfit últimos datos + ruido gaussiano.\"\"\"\n",
    "        n_last = min(degree * 10, len(self.t) // 2)\n",
    "        t_last = self.t[-n_last:]\n",
    "        data_last = self.data[-n_last:]\n",
    "        \n",
    "        t_future = np.linspace(self.t[-1], self.t[-1] + days_ahead, days_ahead)\n",
    "        forecast = np.zeros(days_ahead) #np.zeros((days_ahead, self.data.shape[1]))\n",
    "        \n",
    "        p = np.polyfit(t_last, data_last[:], degree)\n",
    "        forecast[:] = np.polyval(p, t_future) + np.random.normal(0, noise_std, days_ahead)\n",
    "        \n",
    "        return t_future, forecast\n",
    "\n",
    "# # DEMO de USO (¡ejecuta después de Ej.1!)\n",
    "# analyzer = WeatherAnalyzer(days, temps_clean)\n",
    "# smoothed = analyzer.smooth(window=15)\n",
    "# decomp = analyzer.seasonal_decompose()\n",
    "# t_fc, fc = analyzer.forecast(30)\n",
    "# print(analyzer.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Robust I/O + Processed \n",
    "\n",
    "- Save `temps_clean` + `anomalies` to 'processed_weather.npz' (np.savez).\n",
    "\n",
    "- Write subset (first 100 days, columns: days, temp_smooth, anomaly) to 'subset.csv' (savetxt, fmt='%.2f', header).\n",
    "\n",
    "- Function `load_and_validate(filename)`: loads npz/csv, checks shape/inf/NaNs, returns a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('processed_weather.npz', temps=temps_clean, anomalies=anomalies)\n",
    "# subset = np.column_stack([dias[:100], smoothed[0,:100], anomalies[:100]])\n",
    "# np.savetxt('subset.csv', subset, delimiter=',', header='day,temp_smooth,anomaly', fmt='%.3f')\n",
    "\n",
    "def load_and_validate(filename):\n",
    "    # Maneja .npz (load), .csv; check np.isfinite.all(), shape==(?,3)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Questions:\n",
    "\n",
    "- For outliers (IQR method): what fraction of data is removed? Is this conservative/aggressive? Propose alternative (e.g., sigma=3).\n",
    "- Trace @vectorize execution: for data.shape=(365,2), how many calls to smooth(col)? Why results.T? What other vectorizing method you propose?\n",
    "- In seasonal_decompose(): why subtract trend before FFT? What do top-4 frequencies represent (daily/weekly/monthly/yearly)?\n",
    "- Run analyzer.stats() on raw vs smoothed: % std reduction per column? Why does polyfit deg=2 capture trend well?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
