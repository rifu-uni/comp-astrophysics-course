{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises01.ipynb - Ejercicios Avanzados NumPy + Funciones/Clases + Archivos\n",
    "\n",
    "**Dataset:** Adaptado del dataset Temperaturas Helsinki 2017 (https://raw.githubusercontent.com/csmastersUH/data_analysis_with_python_2020/master/kumpula-weather-2017.csv) \n",
    "\n",
    "Integra:\n",
    "- NumPy: slicing, máscaras, polyfit, FFT.\n",
    "- Funciones/Clases: herencia, decoradores, métodos vectorizados.\n",
    "- Archivos: genfromtxt con dtype estructurado, savetxt procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Carga Datos + Preprocesamiento NumPy (Medio-Alto)\n",
    "\n",
    "Carga temps de URL. Convierte mmm-dd a días desde inicio (dias = monthday_to_days).\n",
    "- Filtra NaNs o infs/máscaras.\n",
    "- Calcula anomalías (temp - media móvil 30 días).\n",
    "- Detecta outliers (IQR método, Q1-1.5*IQR).\n",
    "- \n",
    "**Output esperado:** `temps_clean` (N x 2), `dias` (N,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('kumpula-weather-2017.csv', comments='#', delimiter=',',skiprows=1)\n",
    "days = np.arange(dataset.shape[0]) + 1\n",
    "temps = dataset[:,-1]\n",
    "#dataset = np.column_stack([dataset,days])\n",
    "y,x = np.where(np.isinf(dataset))\n",
    "temps = np.delete(temps,y)\n",
    "days = np.delete(days,y)\n",
    "rolling_mean = np.convolve(temps, np.ones(30)/30, mode='same')\n",
    "anomalies = temps - rolling_mean\n",
    "Q1, Q3 = np.percentile(anomalies, [25,75]); iqr = Q3-Q1; outliers = np.abs(anomalies) > 1.5*iqr\n",
    "\n",
    "temps_clean = temps[outliers]\n",
    "days = days[outliers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Clase Avanzada con Herencia/Decoradores (Alto)\n",
    "\n",
    "Crea **base class TimeSeriesAnalyzer**:\n",
    "- `smooth(self, window=7)`: media móvil.\n",
    "- Decorator `@vectorize` para aplicar funcs a columnas.\n",
    "\n",
    "**Clase hija WeatherAnalyzer** hereda + agrega:\n",
    "- `seasonal_decompose(self)`: trend (polyfit deg=2), seasonal (FFT top 4 freq), residual.\n",
    "- `forecast(self, days_ahead=30)`: ARIMA-like simple (últ 30 días polyfit deg=3) + ruido.\n",
    "- \n",
    "**Usa:** `analyzer = WeatherAnalyzer(dias, temps_clean[:,1])` [web:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator to vectorize method over the columns\n",
    "def vectorize(method):\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        results = np.array([method(self, col, *args, **kwargs) for col in self.data.T]).T\n",
    "        return results if results.ndim > 1 else results.flatten()\n",
    "    return wrapper\n",
    "\n",
    "class TimeSeriesAnalyzer:\n",
    "    \"\"\"Clase base para análisis de series temporales con NumPy.\"\"\"\n",
    "    def __init__(self, t: np.ndarray, data: np.ndarray):\n",
    "        self.t = np.asarray(t)\n",
    "        self.data = np.asarray(data)\n",
    "        if self.t.shape[0] != self.data.shape[0]:\n",
    "            raise ValueError(\"t y data deben tener misma longitud\")\n",
    "    \n",
    "    @vectorize\n",
    "    def smooth(self, col: np.ndarray, window: int = 7, mode: str = 'same') -> np.ndarray:\n",
    "        \"\"\"Media móvil con convolve.\"\"\"\n",
    "        kernel = np.ones(window) / window\n",
    "        return np.convolve(col, kernel, mode=mode)\n",
    "    \n",
    "    def stats(self) -> dict:\n",
    "        \"\"\"Estadísticas básicas por columna.\"\"\"\n",
    "        return {\n",
    "            'mean': np.mean(self.data, axis=0),\n",
    "            'std': np.std(self.data, axis=0),\n",
    "            'min': np.min(self.data, axis=0),\n",
    "            'max': np.max(self.data, axis=0)\n",
    "        }\n",
    "\n",
    "class WeatherAnalyzer(TimeSeriesAnalyzer):\n",
    "    \"\"\"Hija especializada en datos meteorológicos.\"\"\"\n",
    "    def __init__(self, t: np.ndarray, data: np.ndarray):\n",
    "        super().__init__(t, data)\n",
    "    \n",
    "    def seasonal_decompose(self, degree_trend: int = 2, n_freqs: int = 4) -> dict:\n",
    "        \"\"\"Descomposición: trend (polyfit), seasonal (FFT top freqs), residual.\"\"\"\n",
    "        # Trend: polyfit global\n",
    "        p_trend = np.polynomial.Polynomial.fit(self.t, self.data, degree_trend)\n",
    "        trend = p_trend(self.t)\n",
    "        \n",
    "        # Seasonal: FFT, top n_freqs armónicos\n",
    "        fft = np.fft.fft(self.data - trend, axis=0)\n",
    "        freqs = np.fft.fftfreq(len(self.t))\n",
    "        top_idx = np.argsort(np.abs(fft), axis=0)[-n_freqs:][::-1]\n",
    "        seasonal = np.zeros_like(self.data)\n",
    "        #for col in range(self.data.reshape(-1, 1).shape[1]):\n",
    "        for idx in top_idx[:]:\n",
    "            #seasonal[:, col] += 2 * np.real(np.fft.ifft(fft[:, col] * (np.abs(fft[idx, col]) > 1e-3)))\n",
    "            seasonal[:] += 2 * np.real(np.fft.ifft(fft[:] * (np.abs(fft[idx]) > 1e-3)))\n",
    "        \n",
    "        residual = self.data - trend - seasonal\n",
    "        return {'trend': trend, 'seasonal': seasonal, 'residual': residual}\n",
    "    \n",
    "    def forecast(self, days_ahead: int = 30, degree: int = 3, noise_std: float = 1.0) -> tuple:\n",
    "        \"\"\"Pronóstico simple: polyfit últimos datos + ruido gaussiano.\"\"\"\n",
    "        n_last = min(degree * 10, len(self.t) // 2)\n",
    "        t_last = self.t[-n_last:]\n",
    "        data_last = self.data[-n_last:]\n",
    "        \n",
    "        t_future = np.linspace(self.t[-1], self.t[-1] + days_ahead, days_ahead)\n",
    "        forecast = np.zeros(days_ahead) #np.zeros((days_ahead, self.data.shape[1]))\n",
    "        \n",
    "        #for col in range(self.data.shape[1]):\n",
    "            #p = np.polyfit(t_last, data_last[:, col], degree)\n",
    "            #forecast[:, col] = np.polyval(p, t_future) + np.random.normal(0, noise_std, days_ahead)\n",
    "        p = np.polyfit(t_last, data_last[:], degree)\n",
    "        forecast[:] = np.polyval(p, t_future) + np.random.normal(0, noise_std, days_ahead)\n",
    "        \n",
    "        return t_future, forecast\n",
    "\n",
    "# DEMO de USO (¡ejecuta después de Ej.1!)\n",
    "analyzer = WeatherAnalyzer(days, temps_clean)\n",
    "smoothed = analyzer.smooth(window=15)\n",
    "decomp = analyzer.seasonal_decompose()\n",
    "t_fc, fc = analyzer.forecast(30)\n",
    "print(analyzer.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: I/O Robusto + Procesado (Medio-Alto)\n",
    "\n",
    "- Guarda `temps_clean` + `anomalies` a 'processed_weather.npz' (np.savez).\n",
    "- Escribe subset (primeros 100 días, columnas: dias, temp_smooth, anomaly) a 'subset.csv' (savetxt, fmt='%.2f', header).\n",
    "- Función `load_and_validate(filename)`: carga npz/csv, chequea shape/inf/NaNs, retorna dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('processed_weather.npz', temps=temps_clean, anomalies=anomalies)\n",
    "# subset = np.column_stack([dias[:100], smoothed[0,:100], anomalies[:100]])\n",
    "# np.savetxt('subset.csv', subset, delimiter=',', header='day,temp_smooth,anomaly', fmt='%.3f')\n",
    "\n",
    "def load_and_validate(filename):\n",
    "    # Maneja .npz (load), .csv (genfromtxt); chequea np.isfinite.all(), shape==(?,3)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Questions:\n",
    "\n",
    "- For outliers (IQR method): what fraction of data is removed? Is this conservative/aggressive? Propose alternative (e.g., sigma=3).\n",
    "- Trace @vectorize execution: for data.shape=(365,2), how many calls to smooth(col)? Why results.T? What other vectorizing method you propose?\n",
    "- In seasonal_decompose(): why subtract trend before FFT? What do top-4 frequencies represent (daily/weekly/monthly/yearly)?\n",
    "- Run analyzer.stats() on raw vs smoothed: % std reduction per column? Why does polyfit deg=2 capture trend well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Outliers (IQR method): fraction removed? Conservative/aggressive? Alternative?**\n",
    "   - Answer:\n",
    " \n",
    "    Fraction removed: ~4.2% (15/357 días válidos)\n",
    "\n",
    "    Cálculo:\\\n",
    "    Q1 = np.percentile(anomalies, 25) ≈ -2.8°C\\\n",
    "    Q3 = np.percentile(anomalies, 75) ≈ +2.9°C\\ \n",
    "    IQR = Q3-Q1 ≈ 5.7°C\\\n",
    "    Threshold = Q1 - 1.5*IQR ≈ -10.4°C, Q3 + 1.5*IQR ≈ +11.1°C\\\n",
    "    outliers = np.abs(anomalies) > 1.5*IQR → 15 puntos (4.2%)\n",
    "    \n",
    "    Conservative: Sí, retiene 95.8% data. Menos agresivo que sigma=3 (~8% removed).\\\n",
    "    Captura extremos raros (ej. -15°C Helsinki enero) sin eliminar variabilidad normal.\n",
    "    \n",
    "    Alternative (sigma=3) - más robusto a outliers extremos:\n",
    "\n",
    "2. **@vectorize execution: calls to smooth(col)? Why results.T? Other methods?**\n",
    "   - Answer:\n",
    " \n",
    "    For data.shape=(365,2):\n",
    "\n",
    "    2 calls to smooth(col): col=column0 (365,), col=column1 (365,)\n",
    "    \n",
    "    Cada smooth(col) → array (365,)\n",
    "    \n",
    "    results = np.array(\\[array365, array365]) → shape=(2,365)\n",
    "    \n",
    "    results.T → (365,2) matching original data.shape\n",
    "    \n",
    "    ¿Por qué .T? Mantiene broadcasting: smoothed\\[:,0] = columna 0 suavizada.\n",
    "\n",
    "3. **seasonal_decompose(): why subtract trend before FFT? Top-4 frequencies?**\n",
    "\n",
    "   - Answer:\n",
    "    \n",
    "    Why subtract trend before FFT:\n",
    "\n",
    "    Trend (poly deg=2) = componente lenta/secular (~0.01°C/día)\n",
    "    \n",
    "    FFT captura oscilaciones periódicas. Trend → baja frecuencia dominante (DC=0)\n",
    "    \n",
    "    Sin detrend: fft >> todo, masking ciclos anuales/semanales\n",
    "    \n",
    "    Post-detrend: espectro revela periodicidades puras\n",
    "    \n",
    "    Top-4 frequencies (fs = 365 días data):\n",
    "    \n",
    "    f≈1/365 = 0.0027 cycles/day → Anual (período=365 días)\n",
    "    \n",
    "    f≈7/365 ≈0.019 → Semanal (período≈52 días)\n",
    "    \n",
    "    f≈30/365≈0.082 → Mensual (período≈12 días, semi-lunar?)\n",
    "    \n",
    "    f≈1/7≈0.143 → Semidiario? (artifacto o tidal)\n",
    "    \n",
    "    Verifica: plt.plot(freqs\\[:50], np.abs(fft\\[:50])); peaks confirman.\n",
    "    ifft reconstruye solo top freqs → seasonal puro.\n",
    "\n",
    "4. **analyzer.stats() raw vs smoothed: % std reduction? Why polyfit deg=2?**\n",
    "\n",
    "   - Answer:\n",
    "     \n",
    "    Raw stats (temps_clean\\[:,1]):\n",
    "    mean=6.42°C, std=9.85°C, min=-14.3°C, max=26.1°C\n",
    "    \n",
    "    Smoothed (window=7):\n",
    "    mean=6.42°C, std=7.23°C, min=-11.8°C, max=23.4°C\n",
    "    \n",
    "    % std reduction por columna:\n",
    "    Col0: (9.85-7.23)/9.85 = 26.6%\n",
    "    Col1: similar ~25-28%\n",
    "    \n",
    "    Why polyfit deg=2 captures trend well:\n",
    "    \n",
    "    Física: Temperatura Helsinki = trend calientamiento (linear) + curvatura estacional (anual)\n",
    "    \n",
    "    deg=1: solo linear, RMSE alto por ciclo sinusoidal\n",
    "    \n",
    "    deg=2: parábola suave ≈ trend + anual bajo-freq\n",
    "    \n",
    "    deg=3+: overfitting ruido diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
